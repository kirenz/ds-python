
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Model &#8212; Data Science with Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Deployment" href="deployment.html" />
    <link rel="prev" title="Data" href="data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="analytics-data-science.html">
   Important concepts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learning.html">
   Learning from data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro-python.html">
   Python toolkit
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Science Lifecycle
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lifecycle.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plan.html">
   Plan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data.html">
   Data
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deployment.html">
   Deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="reference.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://kirenz.github.io/ds-python/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://kirenz.github.io/ds-python//issues/new?title=Issue%20on%20page%20%2Fdocs/model.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/model.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#select-model">
   Select model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-and-evaluate">
   Train and evaluate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-selection">
     Feature selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tuning">
   Tuning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#voting-and-stacking">
   Voting and stacking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-best-model">
   Evaluate best model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-on-test-set">
   Evaluate on test set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   Challenges
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#select-model">
   Select model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-and-evaluate">
   Train and evaluate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-selection">
     Feature selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tuning">
   Tuning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#voting-and-stacking">
   Voting and stacking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-best-model">
   Evaluate best model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-on-test-set">
   Evaluate on test set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   Challenges
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="model">
<h1>Model<a class="headerlink" href="#model" title="Permalink to this headline">#</a></h1>
<p>Once our features have been preprocessed in a format ready for modeling (see <a class="reference internal" href="data.html"><span class="doc std std-doc">Data</span></a>), they can be used in the model selection process.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The type of data preprocessing is dependent on the type of model being fit. <span id="id1">Kuhn and Silge [<a class="reference internal" href="reference.html#id4" title="Max Kuhn and Julia Silge. Tidy Modeling with R. Online book, 2021. URL: https://www.tmwr.org/.">2021</a>]</span> provide recommendations for baseline levels of preprocessing that are needed for various model functions (see <a class="reference external" href="https://www.tmwr.org/pre-proc-table.html">this table</a>).</p>
</div>
<p>The following Jupyter Books provide information about different regression and classification models:</p>
<div class="tip admonition">
<p class="admonition-title">Jupyter Book</p>
<ul class="simple">
<li><p><a class="reference external" href="https://kirenz.github.io/regression/docs/intro.html">Introduction to Regression</a></p></li>
<li><p><a class="reference external" href="https://kirenz.github.io/classification/docs/intro.html">Introduction to Classification</a></p></li>
</ul>
</div>
<p>Next, we discuss some important model selection topics like</p>
<ul class="simple">
<li><p>Model selection</p></li>
<li><p>best fitting model</p></li>
<li><p>mean squared error</p></li>
<li><p>bias-variance trade off.</p></li>
</ul>
<br>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRWlyTZB6YpdYyRpWXdaI5_s8o9MZ5DFk9Gm-cTO4CrrJBHrNgrcyZl4IdktJEMq0e4apMDPpMP46Cb/embed?start=false&loop=false&delayms=3000" frameborder="0" width="820" height="520" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
<br>
<div class="tip admonition">
<p class="admonition-title">Resources</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.google.com/presentation/d/1ZrzKUPZqp7GlCAh4uFpXnvUW6kQTvUgD2G-YZ7B24aM/export/pdf">Download slides</a></p></li>
<li><p>Colab: <a class="reference external" href="https://colab.research.google.com/github/kirenz/data-science-projects/blob/master/ds-first-steps-happy-gdp.ipynb">Regression example: Does money make people happier?</a></p></li>
</ul>
</div>
<p>In the next sections, we’ll discuss the process of model building in detail.</p>
<section id="select-model">
<h2>Select model<a class="headerlink" href="#select-model" title="Permalink to this headline">#</a></h2>
<p>One of the hardest parts during the data science lifecycle can be finding the right model for the job since different types of models are better suited for different types of data and different problems. For some datasets the best model could be a linear model, while for other datasets it is a random forest or neural network. There is no model that is a priori guaranteed to work better. This fact is known as the <em>“No Free Lunch (NFL) theorem”</em> <span id="id2">[<a class="reference internal" href="reference.html#id13" title="David H. Wolpert. The Lack of A Priori Distinctions Between Learning Algorithms. Neural Computation, 8(7):1341–1390, October 1996. URL: https://doi.org/10.1162/neco.1996.8.7.1341, doi:10.1162/neco.1996.8.7.1341.">Wolpert, 1996</a>]</span>.</p>
<br>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTcSDvoljfuWHqUueJAghObDxNULvu-jWuiprqYeeMvA9tITk8gSis1qWsRSAGblEjkExoEiBXFvaPN/embed?start=false&loop=false&delayms=3000" frameborder="0" width="820" height="520" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
<br>
<div class="tip admonition">
<p class="admonition-title">Resources</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.google.com/presentation/d/1ZycVKQLPSHGUv3Mga1CE3BHTL0W_gfszs6SkEh7fzeU/export/pdf">Download slides</a></p></li>
</ul>
</div>
<p>Some of the most common models are (take a look at the Jupyter Books <a class="reference external" href="https://kirenz.github.io/regression/docs/intro.html">Regression</a> and <a class="reference external" href="https://kirenz.github.io/classification/docs/intro.html">Classification</a> for more details):</p>
<ul class="simple">
<li><p>Linear and Polynomial Regression,</p></li>
<li><p>Logistic Regression,</p></li>
<li><p>k-Nearest Neighbors,</p></li>
<li><p>Support Vector Machines,</p></li>
<li><p>Decision Trees,</p></li>
<li><p>Random Forests,</p></li>
<li><p>Neural Networks and</p></li>
<li><p>Ensemble methods like Gradient Boosted Decision Trees (GBDT).</p></li>
</ul>
<p>A model <strong>ensemble</strong>, where the predictions of multiple single learners are aggregated together to make one prediction, can produce a high-performance final model. The most popular methods for creating ensemble models in scikit-learn are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator">Bootstrap aggregating</a>, also called bagging (from bootstrap aggregating)</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees">random forest</a></p></li>
<li><p>Boosting: <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost">AdaBoost</a> and <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting">Gradient Tree Boosting</a></p></li>
</ul>
<p>Each of these methods combines the predictions from multiple versions of the same type of model (e.g., classifications trees).</p>
<p>Note that the only way to know for sure which model is best would be to evaluate them all <span id="id3">[<a class="reference internal" href="reference.html#id6" title="Aurélien Géron. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media, 2019. ISBN 1492032611.">Géron, 2019</a>]</span>. Since this is often not possible, in practice you make some assumptions about the data and evaluate only a few reasonable models. For example, for simple tasks you may evaluate linear models with various levels of regularization as well as some ensemble methods like Gradient Boosted Decision Trees (GBDT). For very complex problems, you may evaluate various deep neural networks.</p>
<p>The following flowchart was provided by scikit-learn developers to give users a bit of a rough guide on how to approach problems with regard to which models to try on your data:</p>
<br>
<a class="bg-primary mb-1 reference internal image-reference" href="../_images/algorithms.png"><img alt="datascience" class="bg-primary mb-1 align-center" src="../_images/algorithms.png" style="width: 800px;" /></a>
<br>
<p>Visit <a class="reference external" href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">this site</a> to interact with the flowchart.</p>
</section>
<section id="train-and-evaluate">
<h2>Train and evaluate<a class="headerlink" href="#train-and-evaluate" title="Permalink to this headline">#</a></h2>
<p>In the first phase of the model building process, a variety of initial models are generated and their performance is compared during model evaluation. As a part of this process, we also need to decide which features we want to include in our model (“feature selection”). Therefore, let’s first take a look at the topic of feature selection.</p>
<section id="feature-selection">
<h3>Feature selection<a class="headerlink" href="#feature-selection" title="Permalink to this headline">#</a></h3>
<p>There are a number of different strategies for feature selection that can be applied and some of them are performed simultaneously with model building.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Feature selection is the process of selecting a subset of relevant features (variables, predictors) for our model.</p>
</div>
<p>If you want to learn more about feature selection methods, review the following content:</p>
<div class="tip admonition">
<p class="admonition-title">Jupyter Book </p>
<ul class="simple">
<li><p><a class="reference external" href="https://kirenz.github.io/feature-engineering/docs/feature-selection.html">Feature Selection</a></p></li>
</ul>
</div>
</section>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h3>
<p>Now we can use the pipeline we created in <a class="reference internal" href="data.html"><span class="doc std std-doc">Data</span></a> (see last section) and combine it with scikit-learn algorithms of our choice:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Use pipeline with linear regression model</span>
<span class="n">lm_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;full_pipeline&#39;</span><span class="p">,</span> <span class="n">full_pipeline</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;lm&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
                         <span class="p">])</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show pipeline as diagram</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s2">&quot;diagram&quot;</span><span class="p">)</span>

<span class="c1"># Fit model</span>
<span class="n">lm_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Obtain model coefficients</span>
<span class="n">lm_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;lm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</section>
<section id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">#</a></h3>
<p>In model evaluation, we mainly assess the model’s performance metrics (using an evaluation set) and examine residual plots (see this <a class="reference external" href="https://kirenz.github.io/regression/docs/diagnostics.html">example for linear regression diagnostics</a>) to understand how well the models work. Our first goal in this process is to shortlist a few (two to five) promising models.</p>
<p>Scikit-learn provides an extensive list of possible metrics to quantify the quality of model predictions:</p>
<div class="tip admonition">
<p class="admonition-title">Metrics</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">Metrics and scoring: quantifying the quality of predictions</a></p></li>
</ul>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>


<span class="c1"># obtain predictions for training data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lm_pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># R squared</span>
<span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> 

<span class="c1"># MSE</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># RMSE</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># MAE</span>
<span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>Show residual plot:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">residplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="mi">80</span><span class="p">});</span>
</pre></div>
</div>
</section>
</section>
<section id="tuning">
<h2>Tuning<a class="headerlink" href="#tuning" title="Permalink to this headline">#</a></h2>
<p>After we identified a shortlist of promising models, it usually makes sense to tune the hyper-paramters of our models.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyper-parameters are parameters that are not directly learnt within algorithms.</p>
</div>
<p>In scikit-learn, hyper-paramters are passed as arguments to the algorithm like “alpha” for Lasso or “K” for the number of neighbors in a K-nearest neighbors model.</p>
<p>Instead of trying to find good hyper-paramters manually, it is recommended to search the hyper-parameter space for the best cross validation score using one of the two generic approaches provided in scikit-learn:</p>
<ul class="simple">
<li><p>for given values, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> exhaustively considers all parameter combinations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> can sample a given number of candidates from a parameter space with a specified distribution.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Tuning</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/grid_search.html">Tuning the hyper-parameters of an estimator</a></p></li>
</ul>
</div>
<p>The <em>GridSearchCV</em> approach is fine when you are exploring relatively few combinations, but when the hyperparameter search space is large, it is often preferable to use <em>RandomizedSearchCV</em> instead <span id="id4">[<a class="reference internal" href="reference.html#id6" title="Aurélien Géron. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media, 2019. ISBN 1492032611.">Géron, 2019</a>]</span>. Both methods use cross-validation (CV) to evaluate combinations of hyperparameter values.</p>
<p>Next, we take a look at an example of hyperparameter tuning with a skicit-learn pipeline (<a class="reference external" href="https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html">scikit-learn developers</a>) for a classification problem (we use the dataset <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py">digits</a>) with logistic regression. In particular, we define a pipeline to search for the best combination of <a class="reference external" href="https://kirenz.github.io/dimension-reduction/docs/pca.html">PCA</a> truncation and classifier regularization:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> 
    <span class="p">(</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span> <span class="n">PCA</span><span class="p">()),</span> 
    <span class="p">(</span><span class="s2">&quot;logistic&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))])</span>

<span class="c1"># Data</span>
<span class="n">X_digits</span><span class="p">,</span> <span class="n">y_digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Parameters of pipelines can be set using ‘__’ separated parameter names:</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pca__n_components&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span>
    <span class="s2">&quot;logistic__C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Gridsearch</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_digits</span><span class="p">,</span> <span class="n">y_digits</span><span class="p">)</span>

<span class="c1"># Show results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameter (CV score=</span><span class="si">%0.3f</span><span class="s2">):&quot;</span> <span class="o">%</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pca__n_components</span></code>: Number of components to keep</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logistic__c</span></code>: Each of the values in Cs describes the inverse of regularization strength. If Cs is as an int, then a grid of Cs values are chosen in a logarithmic scale between 1e-4 and 1e4. Smaller values specify stronger regularization.</p></li>
</ul>
</section>
<section id="voting-and-stacking">
<h2>Voting and stacking<a class="headerlink" href="#voting-and-stacking" title="Permalink to this headline">#</a></h2>
<p>It often makes sense to combine different models since the group (“ensemble”) will usually perform better than the best individual model, especially if the individual models make very different types of errors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Voting can be useful for a set of equally well performing models in order to balance out their individual weaknesses.</p>
</div>
<p>Model <strong>voting</strong> combines the predictions for multiple models of any type and thereby creating an ensemble meta-estimator. scikit-learn provides voting methods for both classification (<a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier">VotingClassifier</a>) and regression (<a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor">VotingRegressor</a>):</p>
<ul class="simple">
<li><p>In <em>classification</em> problems, the idea behind voting is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels.</p></li>
<li><p>In <em>regression</em> problems, we combine different machine learning regressors and return the average predicted values.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Voting regressor</p>
<ul class="simple">
<li><p><a class="reference external" href="https://kirenz.github.io/regression/docs/ensemble.html">Voting regressor example</a></p></li>
</ul>
</div>
<p><strong>Stacked</strong> generalization is a method for combining estimators to reduce their biases. Therefore, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Model stacking is an ensembling method that takes the outputs of many models and combines them to generate a new model that generates predictions informed by each of its members.</p>
</div>
<p>In scikit-learn, the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier">StackingClassifier</a> and <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor">StackingRegressor</a> provide such strategies which can be applied to classification and regression problems.</p>
<p>To learn more about the concept of stacking, visit the <a class="reference external" href="https://stacks.tidymodels.org">documentation of stacks</a>, a R package for model stacking.</p>
</section>
<section id="evaluate-best-model">
<h2>Evaluate best model<a class="headerlink" href="#evaluate-best-model" title="Permalink to this headline">#</a></h2>
<p>After we tuned hyper-parameters and/or performed voting/stacking, we evaluate the best model (system) and their errors in more detail.</p>
<p>In particular, we take a look at the specific errors that our model (system) makes, and try to understand why it makes them and what could fix the problem - like adding extra features or getting rid of uninformative ones, cleaning up outliers, etc. <span id="id5">[<a class="reference internal" href="reference.html#id6" title="Aurélien Géron. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media, 2019. ISBN 1492032611.">Géron, 2019</a>]</span>. If possible, we also display the importance scores of our predictors (e.g. using scikit-learn’s <a class="reference external" href="https://scikit-learn.org/stable/modules/permutation_importance.html">permutation feature importance</a>). With this information, we may want to try dropping some of the less useful features to make sure our model generalizes well.</p>
<p>For example, you could assess possible reasons for the 10 wrongest model predictions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># create dataframe</span>
<span class="n">df_error</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">,</span>
      <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
      <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_train</span>
    <span class="p">})</span>

<span class="c1"># sort by error, select top 10 and get index</span>
<span class="n">error_index</span> <span class="o">=</span> <span class="n">df_error</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;error&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>

<span class="c1"># show corresponding data observations</span>
<span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">error_index</span><span class="p">]</span>

</pre></div>
</div>
<p>After evaluating the model (system) for a while, we eventually have a system that performs sufficiently well.</p>
</section>
<section id="evaluate-on-test-set">
<h2>Evaluate on test set<a class="headerlink" href="#evaluate-on-test-set" title="Permalink to this headline">#</a></h2>
<p>Now is the time to evaluate the final model on the test set. If you did a lot of hyperparameter tuning, the performance will usually be slightly worse than what you measured using cross-validation - because your system ends up fine-tuned to perform well on the validation data and will likely not perform as well on unknown dataset <span id="id6">[<a class="reference internal" href="reference.html#id6" title="Aurélien Géron. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media, 2019. ISBN 1492032611.">Géron, 2019</a>]</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">lm_pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

</pre></div>
</div>
<p>It is important to note that we don’t change the model (system) anymore to make the numbers look good on the test set; the improvements would be unlikely to generalize to new data. Instead, we use the metrics for our final evaluation to make sure the model performs sufficiently well regarding our success metrics from the planning phase.</p>
</section>
<section id="challenges">
<h2>Challenges<a class="headerlink" href="#challenges" title="Permalink to this headline">#</a></h2>
<p>In the following presentation, we cover some typical modeling challenges:</p>
<ul class="simple">
<li><p>Poor quality data</p></li>
<li><p>irrelevant features and feature engineering</p></li>
<li><p>overfitting and regularization</p></li>
<li><p>underfitting</p></li>
</ul>
<br>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQz4smNkQ4Ef0JL2RvMXqlb4RiagKxajxF_QekQhdq8czpX456ly7GgoLKk-tZ5khHSP6J6ztTjMs6X/embed?start=false&loop=false&delayms=3000" frameborder="0" width="820" height="520" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
<br>
<div class="tip admonition">
<p class="admonition-title">Slides</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.google.com/presentation/d/1WPUVfUe4rZu1bt61IwjneHqldhH9nC6U0F_u7Mj_ZL4/export/pdf">Download slides</a></p></li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="deployment.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Deployment</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Jan Kirenz<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>